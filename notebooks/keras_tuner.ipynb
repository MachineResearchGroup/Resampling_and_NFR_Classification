{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_tuner.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j8EGrhnfufb"
      },
      "source": [
        "# Keras e tensorflow\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, Adamax, SGD, RMSprop, Nadam, Ftrl\n",
        "\n",
        "# Keras tuner\n",
        "!pip install keras-tuner -q\n",
        "import kerastuner as kt\n",
        "from kerastuner import HyperModel\n",
        "from kerastuner.tuners import BayesianOptimization\n",
        "\n",
        "# others\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import shutil\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score\n",
        "from contextlib import redirect_stdout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U1k5Wgwf8Pr"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZFCrdq7e8vT"
      },
      "source": [
        "class KerasHyperModel(HyperModel):\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_size,\n",
        "                 output_size,\n",
        "                 optimizer_name):\n",
        "      self.vocab_size = input_size\n",
        "      self.output_size = output_size\n",
        "      self.optimizer_name = optimizer_name\n",
        "\n",
        "    def build(self, hp):\n",
        "      dropout = hp.Float('dropout', 0, 0.5, step=0.1, default=0.5)\n",
        "      act = hp.Choice(name='act', values=['relu', 'tanh', 'elu', 'sigmoid'])\n",
        "      lr = hp.Float('lr', 1e-3, 0.1, step=0.0001)\n",
        "      # l1 = hp.Choice('l1',values=[0.0, 0.01, 0.001, 0.0001])\n",
        "      # l2 = hp.Choice('l2',values=[0.0, 0.01, 0.001, 0.0001])\n",
        "      units = hp.Int('units', min_value=32, max_value=256, step=5)\n",
        "      \n",
        "      opt = None\n",
        "\n",
        "      if self.optimizer_name == 'adam':\n",
        "          opt = Adam(learning_rate=lr)\n",
        "      elif self.optimizer_name == 'adamax':\n",
        "          opt = Adamax(learning_rate=lr)\n",
        "      elif self.optimizer_name == 'nadam':\n",
        "          opt = Nadam(learning_rate=lr)\n",
        "      elif self.optimizer_name == 'rmsprop':\n",
        "          opt = RMSprop(learning_rate=lr)\n",
        "      elif self.optimizer_name == 'sgd':\n",
        "          opt = SGD(learning_rate=lr, momentum=0.0)\n",
        "      elif self.optimizer_name == 'sgdm':\n",
        "          opt = SGD(learning_rate=lr, momentum=0.9)\n",
        "      else:\n",
        "          print('ERROR: Invalid name!')\n",
        "\n",
        "      model = Sequential()\n",
        "\n",
        "      model.add(Dense(units=units,\n",
        "                      input_dim=self.vocab_size,\n",
        "                      activation=act))\n",
        "\n",
        "      model.add(Dropout(dropout))\n",
        "\n",
        "      model.add(Dense(self.output_size, activation='softmax'))\n",
        "      model.compile(optimizer=opt,\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "      return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4bSrZmcf6FL"
      },
      "source": [
        "def get_data(data_num, resampling, num):\n",
        "    train_tfidf = pd.read_csv('/content/drive/MyDrive/PIBIC/datasets/data_'+str(data_num)+'/train/' + resampling + '_tfidf_train(' + str(num) + ').csv')\n",
        "    train_class = pd.read_csv('/content/drive/MyDrive/PIBIC/datasets/data_'+str(data_num)+'/train/' + resampling + '_class_train(' + str(num) + ').csv')\n",
        "\n",
        "    test_tfidf = pd.read_csv('/content/drive/MyDrive/PIBIC/datasets/data_'+str(data_num)+'/test/tfidf_test(' + str(num) + ').csv')\n",
        "    test_class = pd.read_csv('/content/drive/MyDrive/PIBIC/datasets/data_'+str(data_num)+'/test/class_test(' + str(num) + ').csv')\n",
        "\n",
        "    train_tfidf = np.array(train_tfidf)\n",
        "    train_class = np.array(train_class['Class'])\n",
        "\n",
        "    test_tfidf = np.array(test_tfidf)\n",
        "    test_class = np.array(test_class['Class'])\n",
        "\n",
        "    return train_tfidf, train_class, test_tfidf, test_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glQuLu5zfx9D"
      },
      "source": [
        "data_num = [1,2,3,4,5,6,7,8,9,10]\n",
        "resampling = ['origin', 'tomek', 'adasyn', 'smote', 'bdsmote', 'smotetomek']\n",
        "index = [1,2,3,4,5,6]\n",
        "opt_name = ['adamax', 'rmsprop', 'adam']\n",
        "\n",
        "for dn in data_num:\n",
        "  for res in resampling:\n",
        "    for opt in opt_name:\n",
        "      for i in index:\n",
        "        train_tfidf, train_class, test_tfidf, test_class = get_data(dn, res, i)\n",
        "        train_class = LabelBinarizer().fit_transform(train_class)\n",
        "\n",
        "        hypermodel = KerasHyperModel(input_size=train_tfidf.shape[1], output_size=11, optimizer_name=opt)\n",
        "\n",
        "        tuner = BayesianOptimization(\n",
        "            hypermodel,\n",
        "            objective='val_loss',\n",
        "            max_trials=100,\n",
        "            directory='/content/drive/MyDrive/PIBIC/hyperparametrization/detail/'+res+'-data_'+str(dn)+'('+opt+'-'+str(i)+')',\n",
        "            project_name=opt+'-hyper',\n",
        "            executions_per_trial=2\n",
        "        )\n",
        "\n",
        "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=False, patience=5)\n",
        "        tuner.search(train_tfidf, train_class, epochs=60, validation_split=0.125, verbose=1, callbacks=[es])\n",
        "\n",
        "        best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "        with open('/content/drive/MyDrive/PIBIC/hyperparametrization/detail/'+res+'-data_'+str(dn)+'('+opt+'-'+str(i)+').txt', 'w') as f:\n",
        "            f.write(log)\n",
        "            f.write('\\n')\n",
        "\n",
        "        # Salvando: modelo, parametros e arquitetura\n",
        "        best_hp = tuner.get_best_hyperparameters()[0]\n",
        "\n",
        "        path_model_best = '/content/drive/MyDrive/PIBIC/hyperparametrization/hyper_models/data_'+str(dn)+'/'+res+'('+opt+'-'+str(i)+')'\n",
        "        best_model.save(path_model_best)\n",
        "\n",
        "        with open(path_model_best+'/config.json', 'w') as json_file:\n",
        "                    json.dump(best_hp.get_config()['values'], json_file)\n",
        "\n",
        "        with open(path_model_best+'/model_summary.txt', 'w') as f:\n",
        "            with redirect_stdout(f):\n",
        "                best_model.summary()\n",
        "        \n",
        "        # Excluindo pasta\n",
        "        try:\n",
        "          shutil.rmtree('/content/drive/MyDrive/PIBIC/hyperparametrization/detail/'+res+'-data_'+str(dn)+'('+opt+'-'+str(i)+')')\n",
        "        except OSError as e:\n",
        "          print (\"Error: %s - %s.\" % (e.filename, e.strerror))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}