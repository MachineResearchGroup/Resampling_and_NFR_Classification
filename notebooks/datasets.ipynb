{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "datasets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6T42droH5dx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff3276c2-e059-45fe-c1a7-14f19181e650"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from imblearn.under_sampling import EditedNearestNeighbours, RepeatedEditedNearestNeighbours, AllKNN, TomekLinks\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR8x3sYHJPjw",
        "outputId": "27b7e63b-e083-4b13-bb01-2131d1eeed1c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSgtbRzsIQHX"
      },
      "source": [
        "class Resampling:\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.strategie = None\n",
        "        self.name = name\n",
        "\n",
        "        if name == \"enn\":\n",
        "            self.strategie = EditedNearestNeighbours(sampling_strategy='auto',\n",
        "                                                     n_neighbors=3,\n",
        "                                                     kind_sel='all',\n",
        "                                                     n_jobs=-1)\n",
        "        elif name == \"allknn\":\n",
        "            self.strategie = AllKNN(sampling_strategy='auto',\n",
        "                                    n_neighbors=3,\n",
        "                                    kind_sel='all',\n",
        "                                    allow_minority=False,\n",
        "                                    n_jobs=-1)\n",
        "        elif name == \"renn\":\n",
        "            self.strategie = RepeatedEditedNearestNeighbours(sampling_strategy='auto',\n",
        "                                                             n_neighbors=3,\n",
        "                                                             max_iter=100,\n",
        "                                                             kind_sel='all',\n",
        "                                                             n_jobs=-1)\n",
        "\n",
        "        elif name == \"tomek\":\n",
        "            self.strategie = TomekLinks(sampling_strategy='auto',\n",
        "                                        n_jobs=-1)\n",
        "\n",
        "        elif name == \"smote\":\n",
        "            self.strategie = SMOTE(sampling_strategy='auto',\n",
        "                                   k_neighbors=5,\n",
        "                                   n_jobs=-1)\n",
        "\n",
        "        elif name == \"bdsmote\":\n",
        "            self.strategie = BorderlineSMOTE(n_jobs=-1)\n",
        "\n",
        "        elif name == \"adasyn\":\n",
        "            self.strategie = ADASYN(sampling_strategy='auto',\n",
        "                                    n_neighbors=5,\n",
        "                                    n_jobs=-1)\n",
        "\n",
        "        elif name == \"smoteenn\":\n",
        "            self.strategie = SMOTEENN(sampling_strategy='auto',\n",
        "                                      smote=None,\n",
        "                                      enn=None,\n",
        "                                      n_jobs=-1)\n",
        "\n",
        "        elif name == \"smotetomek\":\n",
        "            self.strategie = SMOTETomek(sampling_strategy='auto',\n",
        "                                        smote=None,\n",
        "                                        tomek=None)\n",
        "\n",
        "    def fit_resample(self, x, y):\n",
        "        x_res, y_res = self.strategie.fit_resample(x, y)\n",
        "        return x_res, y_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMFppXmlH7nG"
      },
      "source": [
        "class DataSet:\n",
        "\n",
        "    def define_datasets(self, data, num_data):\n",
        "        resamplings = ['origin', 'tomek', 'smote', 'bdsmote', 'adasyn', 'smotetomek']\n",
        "        k_folds = 10\n",
        "        X = data['RequirementText']\n",
        "        y = data['Class']\n",
        "        print(X)\n",
        "        print(y)\n",
        "        cv = StratifiedShuffleSplit(n_splits=k_folds, test_size=0.2)\n",
        "        indices = cv.split(X, y)\n",
        "\n",
        "        i = 1\n",
        "        for train, test in indices:\n",
        "            vetorClas = LabelEncoder().fit(y[train])\n",
        "            y_train = vetorClas.transform(y[train])\n",
        "            y_test = vetorClas.transform(y[test])\n",
        "\n",
        "            # Tokenize and transform to integer index\n",
        "            tokenizer = Tokenizer()\n",
        "            tokenizer.fit_on_texts(X[train])\n",
        "\n",
        "            x_train = tokenizer.texts_to_matrix(X[train], mode='tfidf')\n",
        "            x_test = tokenizer.texts_to_matrix(X[test], mode='tfidf')\n",
        "\n",
        "            self.export_data_test(num_data, i, x_test, y_test)\n",
        "\n",
        "            for resampling in resamplings:\n",
        "                self.export_data_train(resampling, num_data, i, x_train, y_train)\n",
        "            i += 1\n",
        "\n",
        "    def export_data_train(self, resampling, num_data, index, x_train, y_train):\n",
        "        path1 = '/content/drive/MyDrive/PIBIC/datasets/'+'data_'+str(num_data)+'/train/'+resampling + '_class_train(' + str(index) + ')'\n",
        "        path2 = '/content/drive/MyDrive/PIBIC/datasets/'+'data_'+str(num_data)+'/train/'+resampling + '_tfidf_train(' + str(index) + ')'\n",
        "        if resampling != 'origin':\n",
        "            x_train, y_train = Resampling(resampling).fit_resample(x_train, y_train)\n",
        "\n",
        "\n",
        "        df = {'Class': y_train}\n",
        "        df = pd.DataFrame(df)\n",
        "        df.to_csv(path1 + '.csv')\n",
        "\n",
        "        df = pd.DataFrame(x_train)\n",
        "        df.to_csv(path2 + '.csv')\n",
        "\n",
        "        self.update_dataset_detail(resampling, y_train, num_data, index)\n",
        "\n",
        "    def export_data_test(self, num_data, index, x_test, y_test):\n",
        "        path1 = '/content/drive/MyDrive/PIBIC/datasets/'+'data_'+str(num_data)+'/test/class_test(' + str(index) + ')'\n",
        "        path2 = '/content/drive/MyDrive/PIBIC/datasets/'+'data_'+str(num_data)+'/test/tfidf_test(' + str(index) + ')'\n",
        "\n",
        "        df = {'Class': y_test}\n",
        "        df = pd.DataFrame(df)\n",
        "        df.to_csv(path1+'.csv')\n",
        "\n",
        "        df = pd.DataFrame(x_test)\n",
        "        df.to_csv(path2 + '.csv')\n",
        "\n",
        "        self.update_dataset_detail(None, y_test, num_data, index, test=True)\n",
        "\n",
        "    def update_dataset_detail(self, resampling, y, num_data, index, test=False):\n",
        "        path = '/content/drive/MyDrive/PIBIC/datasets/'+'data_'+str(num_data)+'/detail/dataset_detail(' + str(index) + ').csv'\n",
        "\n",
        "        file = Path(path)\n",
        "\n",
        "        classes = ['A', 'FT', 'L', 'LF', 'MN', 'O', 'PE', 'PO', 'SC', 'SE', 'US', 'total']\n",
        "        counts = self.count_classes(y)\n",
        "\n",
        "        if file.is_file():\n",
        "            df = pd.read_csv(path)\n",
        "            try:\n",
        "                os.remove(file)\n",
        "            except OSError as e:\n",
        "                print(e)\n",
        "\n",
        "            df[resampling] = counts\n",
        "            df.to_csv(path, index=False)\n",
        "\n",
        "        else:\n",
        "            if test:\n",
        "                df = pd.DataFrame({'classes': classes,\n",
        "                                   'test': counts})\n",
        "            else:\n",
        "                df = pd.DataFrame({'classes': classes,\n",
        "                                   resampling: counts})\n",
        "            df.to_csv(path, index=False)\n",
        "\n",
        "    def count_classes(self, y):\n",
        "        y = pd.DataFrame(y)\n",
        "        values = y.value_counts().to_dict()\n",
        "        count = []\n",
        "\n",
        "        for i in range(11):\n",
        "            count.append(values[(i,)])\n",
        "        total = sum(count)\n",
        "        count.append(total)\n",
        "\n",
        "        return count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTptELVYI1iw"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    dataset = DataSet()\n",
        "    warnings.filterwarnings('ignore')\n",
        "    dataset.define_datasets(data=pd.read_csv('/content/drive/MyDrive/PIBIC/datasets/PROMISE_exp_preprocessed.csv', encoding='utf-8'), num_data=3)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}